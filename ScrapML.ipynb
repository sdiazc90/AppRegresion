{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapeando modelo: wrangler\n",
      "Comenzando nuevo archivo para wrangler...\n",
      "Scrapeando página con offset 0...\n",
      "Scrapeando página con offset 48...\n",
      "Scrapeando página con offset 96...\n",
      "Scrapeando página con offset 144...\n",
      "No se encontraron más autos en esta página.\n",
      "Finalizado el modelo wrangler. Total autos guardados: 142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import winsound\n",
    "\n",
    "\n",
    "\n",
    "marca = 'jeep'\n",
    "modelos = ['wrangler']  \n",
    "\n",
    "base_url = \"https://autos.mercadolibre.com.ar/{marca}/{modelo}/_Desde_{offset}_ITEM*CONDITION_2230581_NoIndex_True\"\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; rv:102.0) Gecko/20100101 Firefox/102.0',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15',\n",
    "]\n",
    "\n",
    "\n",
    "def extraer_datos_auto(url_auto, nombre_csv):\n",
    "    try:\n",
    "        headers = {'User-Agent': random.choice(user_agents)}\n",
    "        response_auto = requests.get(url_auto, headers=headers)\n",
    "        if response_auto.status_code == 200:\n",
    "            soup_auto = BeautifulSoup(response_auto.text, 'html.parser')\n",
    "\n",
    "            info_tag = soup_auto.find('span', class_='ui-pdp-subtitle')\n",
    "            if info_tag:\n",
    "                info_text = info_tag.text.strip()\n",
    "                partes = info_text.split('|')\n",
    "                if len(partes) > 1:\n",
    "                    año = partes[0].strip()\n",
    "                    km_text = partes[1].split('·')[0].strip()\n",
    "\n",
    "                    if año.isdigit() and int(año) < 2025:\n",
    "                        script_tag = soup_auto.find('script', type='application/ld+json')\n",
    "                        if script_tag:\n",
    "                            json_content = script_tag.string\n",
    "                            data = json.loads(json_content)\n",
    "\n",
    "                            # Extraer la fecha de publicación exactamente como aparece en el HTML\n",
    "                            fecha_publicacion = \"No disponible\"\n",
    "                            info_subtitle = soup_auto.find('span', class_='ui-pdp-subtitle')\n",
    "                            if info_subtitle:\n",
    "                                fecha_publicacion = info_subtitle.text.strip().split('·')[-1].strip()  # Extraer \"Publicado hace X días\"\n",
    "\n",
    "                            fila = {\n",
    "                                'Marca': data.get('brand', 'No disponible'),\n",
    "                                'Modelo': data.get('name', 'No disponible').split()[1] if len(data.get('name', '').split()) > 1 else \"No disponible\",\n",
    "                                'Año': año,\n",
    "                                'Versión': ' '.join(data.get('name', '').split()[2:]) if len(data.get('name', '').split()) > 2 else \"No disponible\",\n",
    "                                'Color': data.get('color', 'No disponible'),\n",
    "                                'Tipo de combustible': data.get('fuelType', 'No disponible'),\n",
    "                                'Puertas': data.get('numberOfDoors', 'No disponible'),\n",
    "                                'Transmisión': data.get('vehicleTransmission', 'No disponible'),\n",
    "                                'Motor': data.get('vehicleEngine', 'No disponible'),\n",
    "                                'Tipo de carrocería': data.get('bodyType', 'No disponible'),\n",
    "                                'Fecha publicación': fecha_publicacion,\n",
    "                                'Kilómetros': km_text,\n",
    "                                'Precio': data.get('offers', {}).get('price', 'No disponible')                                \n",
    "                            }\n",
    "\n",
    "                            df = pd.DataFrame([fila])\n",
    "                            modo = 'a' if os.path.exists(nombre_csv) else 'w'\n",
    "                            encabezado = not os.path.exists(nombre_csv)\n",
    "\n",
    "                            df.to_csv(nombre_csv, index=False, mode=modo, header=encabezado, encoding='utf-8')\n",
    "                            return True\n",
    "        else:\n",
    "            print(f\"Error al acceder a la página del auto. Código: {response_auto.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error de solicitud: {e}\")\n",
    "    return False\n",
    "\n",
    "def scrapear_pagina(url, nombre_csv):\n",
    "    try:\n",
    "        headers = {'User-Agent': random.choice(user_agents)}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            enlaces_autos = soup.find_all('a', href=True)\n",
    "\n",
    "            autos_encontrados = 0\n",
    "            for enlace in enlaces_autos:\n",
    "                href = enlace['href']\n",
    "                if href.startswith(\"https://auto.mercadolibre.com.ar/MLA-\"):\n",
    "                    if extraer_datos_auto(href, nombre_csv):\n",
    "                        autos_encontrados += 1\n",
    "                    time.sleep(random.uniform(0.1, 0.2))\n",
    "\n",
    "            if autos_encontrados == 0:\n",
    "                print(\"No se encontraron más autos en esta página.\")\n",
    "                return False\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Error al acceder a la página. Código: {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error de solicitud: {e}\")\n",
    "        return False\n",
    "\n",
    "for modelo in modelos:\n",
    "    print(f\"Scrapeando modelo: {modelo}\")\n",
    "    nombre_csv = f'autos_{marca}_{modelo}_mercadolibre.csv'\n",
    "    autos_scrapeados = 0\n",
    "    offset = 0\n",
    "\n",
    "    if os.path.exists(nombre_csv):\n",
    "        df_existente = pd.read_csv(nombre_csv)\n",
    "        autos_scrapeados = len(df_existente)\n",
    "        offset = (autos_scrapeados // 48) * 48\n",
    "        print(f\"Archivo existente detectado para {modelo}. Retomando desde offset {offset}...\")\n",
    "    else:\n",
    "        print(f\"Comenzando nuevo archivo para {modelo}...\")\n",
    "\n",
    "    while True:\n",
    "        url_pagina = base_url.format(marca=marca, modelo=modelo, offset=offset)\n",
    "        print(f\"Scrapeando página con offset {offset}...\")\n",
    "        if not scrapear_pagina(url_pagina, nombre_csv):\n",
    "            break\n",
    "        offset += 48\n",
    "        time.sleep(random.uniform(0.1, 0.2))\n",
    "\n",
    "    if os.path.exists(nombre_csv):\n",
    "        autos_scrapeados = len(pd.read_csv(nombre_csv))\n",
    "\n",
    "    print(f\"Finalizado el modelo {modelo}. Total autos guardados: {autos_scrapeados}\\n\")\n",
    "winsound.Beep(1000, 1000)  # frecuencia 1000 Hz, duración 500 ms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
